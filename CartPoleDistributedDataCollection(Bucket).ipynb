{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CartPoleDistributedDataCollection(Bucket).ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prevelat/Machine_Learning/blob/master/CartPoleDistributedDataCollection(Bucket).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1u9QVVsShC9X"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KEHR2Ui-lo8O",
        "colab": {}
      },
      "source": [
        "# Note: If you haven't installed the following dependencies, run:\n",
        "!apt-get install -y xvfb\n",
        "!pip install 'gym==0.10.11'\n",
        "!pip install 'imageio==2.4.0'\n",
        "!pip install PILLOW\n",
        "!pip install 'pyglet==1.3.2'\n",
        "!pip install pyvirtualdisplay\n",
        "!pip install tf-agents\n",
        "!pip install tensorflow==2.0.0\n",
        "!pip install tensorflow-probability==0.8\n",
        "try:\n",
        "  %%tensorflow_version 2.x\n",
        "except:\n",
        "  pass\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sMitx5qSgJk1",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import base64\n",
        "import imageio\n",
        "import IPython\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL.Image\n",
        "import pyvirtualdisplay\n",
        "import numpy as np\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import time\n",
        "\n",
        "from tf_agents.agents.dqn import dqn_agent\n",
        "from tf_agents.drivers import dynamic_step_driver\n",
        "from tf_agents.environments import suite_gym\n",
        "from tf_agents.environments import tf_py_environment\n",
        "from tf_agents.eval import metric_utils\n",
        "from tf_agents.metrics import tf_metrics\n",
        "from tf_agents.networks import q_network\n",
        "from tf_agents.policies import random_tf_policy\n",
        "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
        "from tf_agents.trajectories import trajectory\n",
        "from tf_agents.utils import common\n",
        "from tf_agents.policies import policy_saver\n",
        "\n",
        "tf.compat.v1.enable_v2_behavior()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NspmzG4nP3b9",
        "colab": {}
      },
      "source": [
        "tf.version.VERSION"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jAuZidP4DZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "os.chdir(\"drive/My Drive/Colab Notebooks\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DATyZPWWcdWe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2n3HOOs4EJQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://cloud.google.com/resource-manager/docs/creating-managing-projects\n",
        "project_id = 'ml-piscine-262622'\n",
        "!gcloud config set project {project_id}\n",
        "\n",
        "policy_bucket_folder = 'gs://ml-piscine-bucket/policy/'\n",
        "data_bucket_folder = 'gs://ml-piscine-bucket/data/'\n",
        "policy_drive_folder = 'policies/'\n",
        "data_drive_folder = 'data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LmC0NDhdLIKY"
      },
      "source": [
        "#### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HC1kNrOsLSIZ",
        "colab": {}
      },
      "source": [
        "replay_buffer_max_length = 100000  # @param {type:\"integer\"}\n",
        "\n",
        "batch_size = 64  # @param {type:\"integer\"}\n",
        "learning_rate = 1e-3  # @param {type:\"number\"}\n",
        "\n",
        "traj_to_collect_per_file = 2000  # @param {type:\"integer\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOfLj0PSh30T",
        "colab_type": "text"
      },
      "source": [
        "#### Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bh1wBwA4zGft",
        "colab_type": "text"
      },
      "source": [
        "Load the CartPole environment from the OpenAI Gym suite. <br/>\n",
        "Usually two environments are instantiated: one for training and one for evaluation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pYEz-S9gEv2-",
        "colab": {}
      },
      "source": [
        "env_name = 'CartPole-v0'\n",
        "env = suite_gym.load(env_name)\n",
        "train_py_env = suite_gym.load(env_name)\n",
        "eval_py_env = suite_gym.load(env_name)\n",
        "train_env = tf_py_environment.TFPyEnvironment(train_py_env)\n",
        "eval_env = tf_py_environment.TFPyEnvironment(eval_py_env)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDanNpi4igIg",
        "colab_type": "text"
      },
      "source": [
        "#### Agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TgkdEPg_muzV",
        "colab": {}
      },
      "source": [
        "fc_layer_params = (100,)\n",
        "\n",
        "q_net = q_network.QNetwork(\n",
        "    train_env.observation_spec(),\n",
        "    train_env.action_spec(),\n",
        "    fc_layer_params=fc_layer_params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfi_g3C0iiRE",
        "colab_type": "text"
      },
      "source": [
        "Now use `tf_agents.agents.dqn.dqn_agent` to instantiate a `DqnAgent`. In addition to the `time_step_spec`, `action_spec` and the QNetwork, the agent constructor also requires an optimizer (in this case, `AdamOptimizer`), a loss function, and an integer step counter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jbY4yrjTEyc9",
        "colab": {}
      },
      "source": [
        "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "train_step_counter = tf.Variable(0)\n",
        "\n",
        "agent = dqn_agent.DqnAgent(\n",
        "    train_env.time_step_spec(),\n",
        "    train_env.action_spec(),\n",
        "    q_network=q_net,\n",
        "    optimizer=optimizer,\n",
        "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
        "    train_step_counter=train_step_counter)\n",
        "\n",
        "agent.initialize()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtKjnwh7OicG",
        "colab_type": "text"
      },
      "source": [
        "#### Policies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvD_UYRI2Cit",
        "colab_type": "text"
      },
      "source": [
        "Download existing Policy if there is one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUmCkvccOlzN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_policy_bucket():\n",
        "  print('----------FETCHING POLICY')\n",
        "  best_avg_ret = 0\n",
        "  all_policies = !gsutil -q ls $policy_bucket_folder\n",
        "  for name in all_policies:\n",
        "    if '.policy.' in name:\n",
        "      s = name[len(policy_bucket_folder):]\n",
        "      split = s.split('.')\n",
        "      if int(split[0]) > best_avg_ret:\n",
        "        best_avg_ret = int(split[0])\n",
        "        folder_name = s\n",
        "  try:\n",
        "    !mkdir $folder_name\n",
        "  except:\n",
        "    pass\n",
        "  if best_avg_ret != 0:\n",
        "    path = policy_bucket_folder + folder_name\n",
        "    print(path)\n",
        "    print('----------DOWNLOADING POLICY FROM BUCKET')\n",
        "    print('--------------------------------------')\n",
        "    print('--------------------------------------')\n",
        "    !gsutil cp -r $path $folder_name\n",
        "    print('--------------------------------------')\n",
        "    print('--------------------------------------')\n",
        "    sub_folder = folder_name + '/' + folder_name\n",
        "    policy = tf.compat.v2.saved_model.load(sub_folder)\n",
        "    !rm -r $folder_name\n",
        "  else:\n",
        "    policy = random_tf_policy.RandomTFPolicy(train_env.time_step_spec(), train_env.action_spec())\n",
        "    print('----------RANDOM POLICY')\n",
        "  return policy, best_avg_ret"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiAuM0fRjK_2",
        "colab_type": "text"
      },
      "source": [
        "#### Replay Buffer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PA8ecbe0zC-S",
        "colab_type": "text"
      },
      "source": [
        "The replay buffer keeps track of data collected from the environment. This tutorial uses `tf_agents.replay_buffers.tf_uniform_replay_buffer.TFUniformReplayBuffer`, as it is the most common. \n",
        "\n",
        "The constructor requires the specs for the data it will be collecting. This is available from the agent using the `collect_data_spec` method. The batch size and maximum buffer length are also required."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vX2zGUWJGWAl",
        "colab": {}
      },
      "source": [
        "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
        "    data_spec=agent.collect_data_spec,\n",
        "    batch_size=train_env.batch_size,\n",
        "    max_length=replay_buffer_max_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CA0XPccljQ3T",
        "colab_type": "text"
      },
      "source": [
        "For most agents, collect_data_spec is a named tuple called Trajectory, containing the specs for observations, actions, rewards, and other items."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_IZ-3HcqgE1z",
        "colab": {}
      },
      "source": [
        "agent.collect_data_spec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sy6g1tGcfRlw",
        "colab": {}
      },
      "source": [
        "agent.collect_data_spec._fields"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZZhJPOljXmg",
        "colab_type": "text"
      },
      "source": [
        "#### Data Collection and Uploading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrHkDtOzzKu5",
        "colab_type": "text"
      },
      "source": [
        "Now execute the chosen policy in the environment for a few steps to collect data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wr1KSAEGG4h9",
        "colab": {}
      },
      "source": [
        "def dict_from_traj(traj):\n",
        "  d = {\n",
        "      'step_type': traj[0].numpy()[0],\n",
        "      'observation': traj[1].numpy()[0],\n",
        "      'action': traj[2].numpy()[0],\n",
        "      'next_step_type': traj[4].numpy()[0],\n",
        "      'reward': traj[5].numpy()[0],\n",
        "      'discount': traj[6].numpy()[0]\n",
        "  }\n",
        "  try:\n",
        "    d['policy_info'] = traj[3].numpy()\n",
        "  except:\n",
        "    d['policy_info'] = traj[3]\n",
        "  return d\n",
        "\n",
        "def collect_step(environment, policy, data_dict, i):\n",
        "  time_step = environment.current_time_step()\n",
        "  action_step = policy.action(time_step)\n",
        "  next_time_step = environment.step(action_step.action)\n",
        "  traj = trajectory.from_transition(time_step, action_step, next_time_step)\n",
        "  data_dict[i] = dict_from_traj(traj)\n",
        "\n",
        "def collect_data(env, policy, steps):\n",
        "  data_dict = dict()\n",
        "  for i in range(steps):\n",
        "    collect_step(env, policy, data_dict, i)\n",
        "  return data_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hcxYBCW0K57",
        "colab_type": "text"
      },
      "source": [
        "Upload"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvAAlNI20OSX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_data_file_name():\n",
        "  i = datetime.datetime.now() - datetime.datetime(1970,1,1)\n",
        "  file_name = str(i.total_seconds()) + '.data.json'\n",
        "  return file_name"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoWvXBqxyrlR",
        "colab_type": "text"
      },
      "source": [
        "## Data Collection loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCC9HsKby5tG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " while True:\n",
        "\n",
        "  # Get Policy\n",
        "  policy, avg = get_policy_bucket()\n",
        "\n",
        "  # Data Collection\n",
        "  print('----------COLLECTING DATA WITH AVG = ', avg)\n",
        "  data = collect_data(train_env, policy, steps=traj_to_collect_per_file)\n",
        "  print('----------DATA COLLECTED')\n",
        "\n",
        "  # Data to Drive\n",
        "  data_file_name = generate_data_file_name()\n",
        "  pd.DataFrame.to_json(pd.DataFrame(data=data),path_or_buf=data_file_name)\n",
        "  print('----------FILE ' + data_file_name + ' CREATED')\n",
        "\n",
        "  # Data to Bucket\n",
        "  path = data_bucket_folder + data_file_name\n",
        "  print('----------UPLOADING NEW DATA')\n",
        "  print('--------------------------------------')\n",
        "  print('--------------------------------------')\n",
        "  !gsutil cp $data_file_name $path\n",
        "  print('--------------------------------------')\n",
        "  print('--------------------------------------')\n",
        "  time.sleep(10)\n",
        "  # !rm $data_file_name\n",
        "  print('----------WAITING TO GENERATE NEW DATA')\n",
        "  time.sleep(60)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}